---
title: "Messenger Analysis"
format: html
---

```{python}
import pandas as pd
import numpy as np
import json
import os
import datetime as dt
import matplotlib as plt
import gensim as gs
```

```{python}
import functions.fbmessenger as fbm
```

```{python}
the_office = fbm.ms_import_data('data/the_office')

# clean messages
the_office['clean_content'] = (the_office[
    'content'
].str.lower()
 .str.strip()
 .str.replace('[^a-z0-9\\s]', '', regex=True)
 .str.replace('\\s{2,}', ' ', regex=True)
 )

the_office = the_office[~the_office['clean_content'].str.contains('reacted to your message')]

the_office['split_content'] = the_office['clean_content'].str.split(' ')
```

```{python}
search_word = 'nah'

the_office_wcount = (the_office[[
    'sender_name', 
    'split_content'
]].explode('split_content')
  .query('split_content == @search_word')
  .value_counts()
  .reset_index()
  .drop('split_content', axis=1)
  .sort_values('count', ascending=False)
  )

the_office_wcount
```

```{python}
the_office['time_diff'] = the_office['timestamp'].diff().fillna(pd.Timedelta(seconds=0))
the_office['time_diff'] = the_office['time_diff'].dt.total_seconds()

conv_cutoff = 600

the_office['new_conv'] = the_office['time_diff'] > conv_cutoff
the_office['conv_num'] = 'Conv ' + the_office['new_conv'].cumsum().astype(str)

conversations = (the_office
                 .groupby('conv_num')
                 ['clean_content']
                 .apply(lambda x: ' '.join(map(str, x)))
                 .reset_index()
                 )
```

```{python}
documents = conversations['clean_content'].tolist()
texts = [doc.split() for doc in documents]
dictionary = gs.corpora.Dictionary(texts)
corpus = [dictionary.doc2bow(text) for text in texts]
ldamodel = gs.models.ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary, passes=20)
for topic in ldamodel.print_topics(num_topics=10, num_words=5):
    print(topic)
```

```{python}
time_diffs = the_office['time_diff']
time_diffs = time_diffs[time_diffs < conv_cutoff]
time_diffs.hist()

np.percentile(the_office['time_diff'], [10, 25, 50, 75, 90])

time_diffs_df = pd.DataFrame(time_diffs)
time_diffs_df['cdf'] = time_diffs_df.rank(method='average', pct=True)
time_diffs_df.sort_values('time_diff').plot(x = 'time_diff', y = 'cdf', grid = True)
```

```{python}
# group messages by sender
the_office_grouped_messages = (the_office
                               .groupby('sender_name')
                               ['content']
                               .apply(lambda x: ' '.join(map(str, x)))
                               .reset_index()
                               )
# get grouped string length
the_office_grouped_messages['word_count'] = the_office_grouped_messages['content'].str.split().str.len()
# sort by word count
the_office_grouped_messages.sort_values('word_count', ascending = False)
```